{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/categorical-variables).**\n\n---\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv',index_col='Id')\nX_test = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv', index_col='Id')","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X_train.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_train.SalePrice\nX_train.drop(['SalePrice'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"nobject_cols = [col for col in X_test.columns if X_test[col].dtype != \"object\"]\nobject_cols = [col for col in X_test.columns if X_test[col].dtype == \"object\"]\nobj_columns = [ col for col in object_cols if X_test[col].isnull().any()]\nnobj_columns = [ col for col in nobject_cols if X_test[col].isnull().any()]\nlow_cardinality_cols = [col for col in object_cols if X_test[col].nunique() < 10]","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nX_obj = X_train.copy()\nX_test_obj = X_test.copy()\noh_encoder =OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(oh_encoder.fit_transform(X_obj[low_cardinality_cols])) \nOH_cols_test = pd.DataFrame(oh_encoder.transform(X_test_obj[low_cardinality_cols])) \nOH_cols_train.index = X_obj.index\nOH_cols_test.index = X_test_obj.index\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_obj.drop(object_cols, axis=1)\nnum_X_test = X_test_obj.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nX_obj = pd.concat([num_X_train, OH_cols_train], axis=1)\nX_test_obj = pd.concat([num_X_test, OH_cols_test], axis=1)\n","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Int64Index([1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470,\n            ...\n            2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919],\n           dtype='int64', name='Id', length=1459)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nX_nobj_plus = X_obj.copy()\nX_test_nobj_plus = X_test_obj.copy()\n\nfor col in nobj_columns:\n    X_nobj_plus[col + '_was_missing'] = X_nobj_plus[col].isnull()\n    X_test_nobj_plus[col + '_was_missing'] = X_test_nobj_plus[col].isnull()\n\nimpute = SimpleImputer()\nfinal_X_nobj = pd.DataFrame(impute.fit_transform(X_nobj_plus))\nfinal_X_test_nobj = pd.DataFrame(impute.transform(X_test_nobj_plus))\n\n# Fill in the lines below: imputation removed column names; put them back\nfinal_X_nobj.columns = X_nobj_plus.columns\nfinal_X_test_nobj.columns = X_test_nobj_plus.columns\nfinal_X_nobj.index = X_obj.index\nfinal_X_test_nobj.index = X_test_obj.index","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=100,random_state=0)\nmodel.fit(final_X_nobj,y)\npred = model.predict(final_X_test_nobj)\noutput = pd.DataFrame({'Id': final_X_test_nobj.index,\n                       'SalePrice': pred})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"        Id  SalePrice\n0     1461  127014.58\n1     1462  155681.00\n2     1463  178072.01\n3     1464  181484.90\n4     1465  199703.96\n...    ...        ...\n1454  2915   84244.11\n1455  2916   86480.50\n1456  2917  151158.99\n1457  2918  112947.00\n1458  2919  227762.84\n\n[1459 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>127014.58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>155681.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>178072.01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>181484.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>199703.96</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>84244.11</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>86480.50</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>151158.99</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>112947.00</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>227762.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Keep going\n\nWith missing value handling and categorical encoding, your modeling process is getting complex. This complexity gets worse when you want to save your model to use in the future. The key to managing this complexity is something called **pipelines**. \n\n**[Learn to use pipelines](https://www.kaggle.com/alexisbcook/pipelines)** to preprocess datasets with categorical variables, missing values and any other messiness your data throws at you.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161289) to chat with other Learners.*","metadata":{}}]}